## FCOS: Fully Convolutional One-Stage Object Detection
阅读笔记 by **luo13**  
2020-3-15  

文章贡献：  
1、提出了一种新的anchor-free的方法  
2、网络设计中的超参数减少  
3、实验好于其他的一阶段anchor-based方法  
4、不用anchor，不需要提取出部分的区域进行回归或者分类，让神经网络的任务回归到最简单的像素级别的操作。

之前看center-loss的时候就觉得如果待检测目标的中心点被遮挡，检测效果会不会变差，这篇文章就不检测中心，而是回归每一个点到bbox四个边界的距离。这在一定程度上可以缓解中心点被遮挡的问题。同时，这样的操作也增加了正样本的数量，可以一定程度上缓解正负样本不均衡的问题。    
![效果图](../../../img/fcos/效果图.png)  

![网络结构](../../../img/fcos/网络结构.png)  
网络结构很简单，backbone可以替换，使用FPN作为neck，不知道FPN是不是都会再额外进行两次下采样？这个得找时间去了解一下，FPN的每一层featuremap都会有一个预测分支，分支里面包括分类分支、中心偏移分支以及回归分支，其中分类分支和中心偏移分支大部分权重共享（不过文章提到了，其实中心偏移分支与回归分支共享权重效果会更好，但是因为论文发出去了就懒得改了。）多层预测的原因是希望通过不同分支去预测不同尺度的物体，从而把重叠的物体分离开来，这个和guided-anchor那篇论文的做法有点相似，如果还是存在分离不开的情况，那么有矛盾的点就去回归最小的那个边框。值得注意的是FPN分配上不是使用IoU阈值作为分配标准，而是使用边框的最长边进行分配，避免了IoU的计算。

![目标值](../../../img/fcos/目标值.png)  
回归值得目标。这里没有像centerNet，cornerNet那样考虑下采样的误差。  

![loss](../../../img/fcos/loss.png)  
这是部分的loss，后面还需要加入中心偏移误差  

![center-ness](../../../img/fcos/center-ness.png)  
![center-ness计算](../../../img/fcos/center-ness计算.png)  
这种方式比直接收缩正样本区域会更合理，感觉上这部分和类别得分没有很好的结合起来，毕竟类别得分回归的时候还是二分类问题，但是明显边缘属于这一个类别的概率会第一点。还有一个是centerness的得分是不稳定的，网上有人说这一部分的loss在训练过程中是下降很慢的，但加入了这个的确会有效果。不是很明白为什么可以使用BCE，感觉是一个回归问题才对。  


