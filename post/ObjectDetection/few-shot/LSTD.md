## LSTD: A Low-Shot Transfer Detector for Object Detection
阅读笔记 by **luo13**  
2020-3-9  

虽然有几篇论文都说自己是第一个关注这个领域的，但我感觉这篇文章应该是第一个。  

**文章贡献**  
1、提出一个LSTD网络结构  
2、提出用于少样本检测的训练方法  
3、提出两个正则化的方法用于让模型能从原域获得更多信息  

**网络结构**  
![lstd网络结构](../../../img/LSTD/lstd网络结构.png)  
把SSD和Faster-RCNN结合了起来，文章说Faster-RCNN的回归部分是每个类别都不一样，这个说法我不是很懂。作者在边界框回归模块采用了SSD的结构，相当于把SSD改成了一个RPN网络。在分类模块则采用了Faster-RCNN的结构，主要是说RoIPooling。  

**训练方法**  
这里想要表达的意思是少样本检测毕竟还是属于少样本学习，可能还是需要一个大数据的原域去学习基本的特征，再想办法将原域信息和小尺寸的原域信息结合起来。  

**正则化方法**  
![训练结构](../../../img/LSTD/训练结构.png)  
这个正则化方法总感觉有些暴力，第一个BD正则化是从backbone中选取一层特征层，将其特征层与gt做交集，得到不属于gt的部分，要做的是惩罚gt以外的响应。  
![bd](../../../img/LSTD/bd.png)  
![bd效果](../../../img/LSTD/bd效果.png)  

第二个是因为考虑到原域和目标域的类别虽然是不一样的，但是可以尽量利用原域的信息，具体做法是增加了一个分类分支，这个分类分支分类结果是原域的类别，再将其与原域分类类别做交叉熵损失，从而让目标域分类分支学习到原域能提取到的信息。  
![tk](../../../img/LSTD/tk.png)  
![loss1](../../../img/LSTD/loss1.png)  
![loss2](../../../img/LSTD/loss2.png)  
![loss3](../../../img/LSTD/loss3.png)  
![loss4](../../../img/LSTD/loss4.png)  
![tk效果](../../../img/LSTD/tk效果.png)  
因为原域没有cow的类别，但是cow的特征和bear很像，所以在原域可以分类为bear的特征在目标域应该可以分类为cow  

训练时batch size是32  
![训练策略](../../../img/LSTD/训练策略.png)  
训练策略原域和目标域是一样的

小结：
1、将SSD改成了RPN，让网络学会背景和前景。  
2、两个正则化的方法虽然感觉很暴力，但可以借鉴一下。
